collapse = FALSE
)
library(parallel)
library(MSwM)
# Import the data
data(traffic)
names(traffic)
# OLS regression
olsLVS = lm(NDead ~ Temp + Prec, data = traffic)
summary(olsLVS)
#
#****************************************************************************************
# Markov Switching
?msmFit
# MS (k is number of regimes, 6 is for means of 5 variables
# + 1 for volatility)
msLVS = msmFit(olsLVS, k = 2, sw = rep(TRUE, 4))
library(Matrix)
library(plm)
library(tvReg)
set.seed(100)
#
tau <- seq(1:1000)/1000
#
beta <- data.frame(beta1 = sin(2 * pi * tau), beta2 = 2 * tau)
plot(beta$beta1, type = 'l')
plot(beta$beta2, type = 'l')
#
X1 <- rnorm(1000)
X2 <- rchisq(1000, df = 4)
error <- rt(1000, df = 10)
#
y <- apply(cbind(X1, X2) * beta, 1, sum) + error # X * Beta + Error
data <- data.frame(y = y, X1 = X1, X2 = X2)
View(data)
coef.lm <- stats::lm(y ~ 0 + X1 + X2, data = data)$coef
coef.lm
model.tvLM <- tvLM(y ~ 0 + X1 + X2, data = data)
model.tvLM
plot(beta$beta1, type = 'l')
plot(beta$beta2, type = 'l')
plot(tau, beta[, 1], type = "l", main = "",
ylab = expression(beta[1]),
xlab = expression(tau),
ylim = range(beta[, 1], model.tvLM$tvcoef[, 1]),
col = 1)
abline(h = coef.lm[1],
col = 2)
lines(tau, model.tvLM$coefficients[, 1],
col = 4)
legend("topright", c(expression(beta[1]), "lm", "tvlm"),
col = c(1, 2, 4), bty = "n",
lty = 1, cex = 0.8)
#
#****************************************************************************************
# Intervalo de Confianza al 90% de los coeficientes TVP
model.tvLM.90 <- confint(model.tvLM, level = 0.9, runs = 50)
plot(model.tvLM.90)
tt <- (1:1000)/1000
beta <- cbind(0.5 * cos(2 * pi * tt), (tt - 0.5)^2)
y <- numeric(1000)
y[1] <- 0.5
y[2] <- -0.2
y[t] <- y[(t - 1):(t - 2)] %*% beta[t, ] + rnorm(1)
for (t in 3:1000) {
y[t] <- y[(t - 1):(t - 2)] %*% beta[t, ] + rnorm(1)
}
Y <- tail(y, 500)
model.ar.2p <- ar.ols(Y, aic = FALSE,
order = 2,
intercept = FALSE,
demean = FALSE)
model.tvAR.2p <- tvAR(Y, p = 2,
type = "none",
est = "ll")
model.tvAR.80 <- confint(model.tvAR.2p,
tboot = "wild2",
level = 0.8, runs = 50)
plot(model.tvAR.80)
?tvAR
library(stargazer)
install.packages("stargazer")
install.packages("sampleSelection")
library(stargazer)
library(sampleSelection)
library(maxLik)
library(miscTools)
library(sampleSelection)
#
data(Mroz87)
View(Mroz87)
names(Mroz87)
ols = lm(wage >= 5 ~ educ, data=subset(Mroz87, lfp==1) )
m <- heckit(lfp ~ educ + age + kids5 + kids618 + nwifeinc,
wage >= 5 ~ educ, data = Mroz87 )
stargazer(ols, m, title="Married women's wage regressions", type="text",df=FALSE, digits=4)
?heckit
library("mlogit")
install.packages('mlogit')
library(mlogit)
data("HC", package = "mlogit")
names(HC)
?dfidx
View(HC)
HC <- dfidx(HC, varying = c(2:8, 10:16), choice = "depvar")
View(HC)
HC <- dfidx(HC, varying = c(2:8, 10:16), choice = "depvar")
data("HC", package = "mlogit")
names(HC)
HC <- dfidx(HC, varying = c(2:8, 10:16), choice = "depvar")
cooling.modes <- idx(HC, 2) %in% c('gcc', 'ecc', 'erc', 'hpc')
room.modes <- idx(HC, 2) %in% c('erc', 'er')
# installation / operating costs for cooling are constants,
# only relevant for mixed systems
HC$icca[! cooling.modes] <- 0
HC$occa[! cooling.modes] <- 0
# create income variables for two sets cooling and rooms
HC$inc.cooling <- HC$inc.room <- 0
HC$inc.cooling[cooling.modes] <- HC$income[cooling.modes]
HC$inc.room[room.modes] <- HC$income[room.modes]
# create an intercet for cooling modes
HC$int.cooling <- as.numeric(cooling.modes)
nl <- mlogit(depvar ~ ich + och +icca + occa + inc.room + inc.cooling + int.cooling | 0, HC,
nests = list(cooling = c('gcc','ecc','erc','hpc'),
other = c('gc', 'ec', 'er')), un.nest.el = TRUE)
summary(nl)
nl <- mlogit(depvar ~ ich + och +icca + occa + inc.room + inc.cooling + int.cooling | 0, HC,
nests = list(cooling = c('gcc','ecc','erc','hpc')), un.nest.el = TRUE)
nl <- mlogit(depvar ~ ich + och +icca + occa + inc.room + inc.cooling + int.cooling | 0, HC,
nests = list(cooling = c('gcc','ecc','erc','hpc'),
other = c('gc')), un.nest.el = TRUE)
summary(nl)
class("a")
class("a")
class("a")
class("R">"Python"); "R" > "Python"; 5 < 2
class(2); class(as.integer(2)); class("2")
ObjetoGuardado <- c(1,2,3,5,7,11,13,17,10)
print(ObjetoGuardado)
ObjetoGuardado
ObjetoGuardado + 5
ObjetoGuardado*5
ObjetoGuardado**(1/2)
log(ObjetoGuardado)
exp(ObjetoGuardado)
round(exp(ObjetoGuardado), 2)
ls() # "ls" lista todos los elementos contenidos en Global Enviroment
class(ObjetoGuardado)
I <- c(1, 1, 1, 1, 1, 1, 1, 1, 1)
ObjetoGuardado %*% I # Producto punto entre vectores
ListaGuardada <- list(c("Omar", "José"), c(24,29), c(TRUE, FALSE))
View(ListaGuardada)
ListaGuardada
class(ListaGuardada)
M_object <-matrix(ObjetoGuardado, nrow = 3, ncol = 3) #Generamos una matriz a partir del vector
M_object
diagonal <- diag(3) #Generamos una matríz identidad de 3*3
diagonal
M_object%*%diagonal #
t(M_object)
t(M_object)%*%diagonal #
solve(M_object) #Matriz inversa
M_object%*%solve(M_object)
ListaGuardada
miData = data.frame(ListaGuardada) #Generamos un DataFrame a partir del objeto clase lista
miData #Imprimimos
View(miData)
names(miData) = c("Nombre", "Edad", "PEA")#Le damos nombre a las columnas
miData #Imprimimos
View(miData)
solve(M_object)
names(miData) = c("Nombre", "Edad", "PEA")#Le damos nombre a las columnas
names(miData) = c("Nombre", "Edad", "PEA")#Le damos nombre a las columnas
miData #Imprimimos
ListaGuardada <- list(c("Omar", "José"), c(24,29), c(TRUE, FALSE))
miData = data.frame(ListaGuardada) #Generamos un DataFrame a partir del objeto clase lista
View(miData)
names(miData) = c("Nombre", "Edad", "PEA", "Talla")#Le damos nombre a las columnas
ObjetoGuardado
ObjetoGuardado[9]
ObjetoGuardado[c(8,9)]
ObjetoGuardado[4:9]
M_object
M_object[9]
M_object[3:5]
M_object[ , 3]
miData['Nombre']
names(miData) = c("Nombre", "Edad", "PEA")#Le damos nombre a las columnas
miData['Nombre']
miData[2]
miData[1:2]
miData[2, 'Nombre']
miData$Edad
length(ObjetoGuardado)
sum(ObjetoGuardado)
mean(ObjetoGuardado)
sd(ObjetoGuardado)
###Las funciones necesitan ARGUMENTOS, en el caos siguiente el argumento es el tamaño de la muestra
?sample
ObjetoGuardado
sample(ObjetoGuardado, 3, replace = FALSE)
sample(ObjetoGuardado, 10, replace = TRUE)
###Para conocer los argumentos de una funcion, se puede utilizar args()
args(sample)
###Funciones creadas
m_podada <- function(x, n){
# Funcion de la media podada
N = length(x)
x = x[ (n+1) : (N-n) ]
sum(x) / length(x)
}
ObjetoGuardado
sort(ObjetoGuardado)
m_podada(sort(ObjetoGuardado),2)
mean(ObjetoGuardado)
###Como alternativa podemos usar bibliotecas que contengan un proceso como el que ocuparemos
install.packages("AER")
library(AER)
# Con  Dependencias
library(car)
library(carData)
library(lmtest)
library(zoo)
library(sandwich)
library(survival)
library(AER)
plot(ObjetoGuardado)
plot(ObjetoGuardado, type = "l")
### Librería para descargar series financieras y graficarlas
install.packages("quantmod")
install.packages("highcharter")
install.packages("ggplot2")
library(xts)
library(TTR)
library(quantmod)
library(highcharter)
library(ggplot2)
options("getSymbols.warning4.0" = FALSE)
### Descargamos la serie de las acciones de Amazon
getSymbols("AMZN")
View(AMZN)
head(AMZN, 2)
### Gráfico
hchart(AMZN)
getSymbols("APLL")
### Descargamos la serie de Nasdaq
getSymbols("NDAQ")
head(NDAQ, 2)
### Gráfico
hchart(NDAQ)
##
class(AMZN)
### Análisis exploratorio de datos con ggplot
ggplot(data = miData, aes(x = Nombre, y = Edad, group = 1)) +
geom_line(color = "red") + geom_point(color = "blue") +
ggtitle("Edades")
ListaGuardada <- list(c("Omar", "Jose"), c(24,29), c(TRUE, FALSE))
miData = data.frame(ListaGuardada) #Generamos un DataFrame a partir del objeto clase lista
names(miData) = c("Nombre", "Edad", "PEA")#Le damos nombre a las columnas
load("~/Documents/Personal/Cursos_CIDE/Estadistica_II_2021/Estadistica-II-2021/R/Clase_0.R")
load("~/Documents/Personal/Cursos_CIDE/Estadistica_II_2021/Estadistica-II-2021/R/Clase_0.R")
"R" > "Python"
"R" < "Python"
knitr::opts_chunk$set(echo = TRUE)
plot( c(1, 2, 3) , type = 'l')
plot( c(1, 2, 3) , type = 'l')
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
install.packages("rmarkdown")
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
ufo <- read_csv("ufo.csv")
ufo
ufo %>% head()
ufo <- read_csv("ufo.csv")
ufo %>% head()
ufo.count <- ufo %>% count()
paste("There were", ufo.count, "UFO sightings")
ufo$state %>% unique() %>% length()
ufo$state %>% unique()
ufo %>%
group_by(state) %>%
summarise(avg.duration = mean(`duration (seconds)`)) %>%
arrange(desc(avg.duration))
ufo %>%
group_by(state) %>%
summarise(number.sightings = n()) %>%
arrange(desc(number.sightings))
ufo %>%
group_by(shape) %>%
summarise(shape.count = n()) %>%
arrange(desc(shape.count))
?qchisq
qchisq(.95, 7)
qchisq(0.95, 7)
qchisq(0.05, 7)
knitr::opts_chunk$set(echo = TRUE)
install.packages("rmarkdown")
plot( c(1, 2, 3) , type = 'l')
knitr::opts_chunk$set(echo = TRUE)
install.packages("tidyverse")
library(tidyverse)
ufo <- read_csv("ufo.csv")
ufo %>% head()
View(ufo)
ufo.count <- ufo %>% count()
paste("Se localizaron ", ufo.count, "avistamientos de ovnis")
View(ufo)
ufo$state %>% unique() %>% length()
ufo$state %>% unique()
ufo %>%
group_by(state) %>%
summarise(avg.duration = mean(`duration (seconds)`)) %>%
arrange(desc(avg.duration))
ufo %>%
group_by(state) %>%
summarise(number.sightings = n()) %>%
arrange(desc(number.sightings))
ufo %>%
group_by(shape) %>%
summarise(shape.count = n()) %>%
arrange(desc(shape.count))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
students <-read_csv("students.csv")
schools <- read_csv("schools.csv")
students %>% head()
schools %>% head()
data2 = left_join(students, schools, by = c("school_name"))
data2 %>% head()
school_count <- students$school_name %>%
unique() %>%
length()
school_count
student_count <-  students %>% nrow()
student_count
mean_reading_score <- summarize(students, mean(reading_score))
mean_math_score <- summarize(students, mean(math_score))
percentage_passing_reading <- students %>%
filter(reading_score > 70) %>%
nrow() * 100 / student_count %>%
round(2)
percentage_passing_reading
percentage_passing_math <-  students %>%
filter(math_score > 70) %>%
nrow() * 100 / student_count %>%
round(2)
percentage_passing_math
overall_passing_rate <- (percentage_passing_math + percentage_passing_reading) / 2
overall_passing_rate
students %>%
group_by(school_name) %>%
summarize(avg.reading=mean(reading_score), avg.math=mean(math_score))
students %>%
group_by(school_name, grade) %>%
summarize(avg.reading=mean(reading_score), avg.math=mean(math_score))
total_budget <- schools %>%
summarize(sum(budget))
total_budget <- total_budget %>% sapply(as.numeric)
mean_math_score <- mean_math_score %>% sapply(as.numeric)
mean_reading_score <- mean_reading_score %>% sapply(as.numeric)
paste("Escuelas: ", school_count)
paste("Estudiantes: ", student_count)
paste("Presupuesto total: ", total_budget)
paste("Promedio de calificación de lectura: ", mean_reading_score)
paste("Promedio de calificación de matemáticas: ", mean_math_score)
paste("% de aprovación en lectura: ", percentage_passing_reading)
paste("% de aprovación en matemáticas: ", percentage_passing_math)
paste("Tasa de aprobación general: ", overall_passing_rate)
district_summary <- tribble(
~Total.Schools, ~Total.Students, ~Total.Budget, ~Avg.Math, ~Avg.Reading, ~Percent.Passing.Math, ~Percent.Passing.Reading, ~Overall.Passing,
school_count, student_count, total_budget[[1]], mean_math_score[[1]], mean_reading_score[[1]], percentage_passing_reading, percentage_passing_math[[1]], overall_passing_rate
)
district_summary
school_summary.tb <- data2 %>%
group_by(type, school_name) %>%
summarise(Avg.Reading.Score=mean(reading_score),
Avg.Math.Score=mean(math_score),
Total.Students=n(),
Budget = mean(budget),
Per.Student.Budget = mean(budget) / n()
)
school_summary.tb %>% head(15)
0.48^2
(0.48^2)*e^(-0.48)/2
(0.48^2)*exp(-0.48)/2
1-.619-.297-.071
# Series de Tiempo, Noviembre de 2020
# Clase 18. Cointegracion (2)
#****************************************************************************************
#install.packages("ggplot2")
#install.packages("dplyr")
#install.packages("vars", dependencies = TRUE)
#
library(ggplot2)
library(dplyr)
library(MASS)
library(strucchange)
library(zoo)
library(sandwich)
library(urca)
library(lmtest)
library(vars)
#
#****************************************************************************************
setwd("/Users/benjaminolivavazquez/Documents/Personal/Cursos_UNAM/SERIES_2021-I/Series-de-Tiempo-Fall2020/Clase_18")
getwd()
load("Datos_Ad.RData")
Datos <- ts(Datos_Ad[7: 11],
start = c(2000, 1),
end = c(2019, 7),
freq = 12)
LDatos <- log(Datos)
DLDatos <- diff(log(Datos, base = exp(1)),
lag = 1,
differences = 1)
plot(cbind(LDatos, DLDatos),
plot.type = "m", nc = 2,
col = c("darkgreen", "darkblue", "darkred", "orange", "purple"),
main = "Comparacion de Series en Diferencias",
xlab = "Tiempo")
VARselect(LDatos, lag.max = 10, type = "both")
VARselect(LDatos, lag.max = 10, type = "trend")
VARselect(LDatos, lag.max = 10, type = "const")
VARselect(LDatos, lag.max = 10, type = "none")
VAR_1 <- VAR(LDatos, p = 3, type = "both")
summary(VAR_1)
summary(VAR_1, equation = "INPC_Ad")
plot(VAR_1)
plot(VAR_1, names = "IPI_Ad")
knitr::opts_chunk$set(echo = TRUE)
#install.packages("ggplot2")
#install.packages("dplyr")
#install.packages(stats)
#install.packages("MASS")
#install.packages("strucchange")
#install.packages("zoo")
#install.packages("sandwich")
#install.packages("urca")
#install.packages("lmtest")
#install.packages("vars")
#
library(ggplot2)
library(dplyr)
library(stats)
library(MASS)
library(strucchange)
library(zoo)
library(sandwich)
library(urca)
library(lmtest)
library(vars)
load("Datos_Ad.RData")
head(Datos_Ad)
Datos_Ad
View(Datos_Ad)
Datos <- ts(Datos_Ad[7: 11],
start = c(2000, 1),
end = c(2021, 7),
freq = 12)
LDatos <- log(Datos)
DLDatos <- diff(log(Datos, base = exp(1)),
lag = 1,
differences = 1)
plot(cbind(LDatos, DLDatos),
plot.type = "m", nc = 2,
col = c("darkgreen", "darkblue", "darkred", "orange", "purple"),
main = "Comparacion de Series en Diferencias",
xlab = "Tiempo")
VARselect(LDatos, lag.max = 10, type = "both")
VARselect(LDatos, lag.max = 10, type = "trend")
VARselect(LDatos, lag.max = 10, type = "const")
VARselect(LDatos, lag.max = 10, type = "none")
summary(ca.jo(LDatos, type = "trace", ecdet = "trend", K = 2, spec = "longrun"))
summary(ca.jo(LDatos, type = "trace", ecdet = "const", K = 2, spec = "longrun"))
summary(ca.jo(LDatos, type = "trace", ecdet = "none", K = 2, spec = "longrun"))
summary(ca.jo(LDatos, type = "eigen", ecdet = "trend", K = 2, spec = "longrun"))
summary(ca.jo(LDatos, type = "eigen", ecdet = "const", K = 2, spec = "longrun"))
summary(ca.jo(LDatos, type = "eigen", ecdet = "none", K = 2, spec = "longrun"))
CA_1 <- ca.jo(LDatos, type = "trace", ecdet = "const", K = 2, spec = "longrun")
summary(CA_1)
View(Datos_Ad)
TT <- ts(c(1:259),
start = c(2000, 1),
end = c(2021, 7),
freq = 12)
U <- LDatos[ , 1] + 0.7559141*LDatos[ , 2]
- 0.3623270*LDatos[ , 3]
- 5.0035388*LDatos[ , 4]
+ 4.2690269*LDatos[ , 5]
- 3.2113796
plot(U,
main = "Residuales de la Ecuación de Cointegración",
type = "l",
col = "darkred")
+ 3.2113796
U <- LDatos[ , 1] - 0.7559141*LDatos[ , 2]
+ 0.3623270*LDatos[ , 3]
+ 5.0035388*LDatos[ , 4]
- 4.2690269*LDatos[ , 5]
+ 3.2113796
plot(U,
main = "Residuales de la Ecuación de Cointegración",
type = "l",
col = "darkred")
summary(ur.df(U, type = "trend", lags = 4))
summary(ur.df(U, type = "drift", lags = 4))
summary(ur.df(U, type = "none", lags = 4))
summary(ur.df(DLDatos[, 5], type = "trend", lags = 4))
summary(ur.df(DLDatos[, 5], type = "drift", lags = 4))
summary(ur.df(DLDatos[, 5], type = "none", lags = 4))
